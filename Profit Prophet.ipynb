{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profit Prophet: The Stock Market ML Predictor\n",
    "\n",
    "This project uses LSTM machine learning to make predictions on the stock market and recommend a course of action.\n",
    "\n",
    "## Stock Data\n",
    "\n",
    "TBD. What specific data should we collect for the LSTM?\n",
    "\n",
    "## Approach\n",
    "\n",
    "First we train an LSTM model for the [TBD. Aggreggated index? Each stock?] to get a forecast of the market based on pure numeric data.\n",
    "\n",
    "Simultaneously, we read the news and use ML to catagorize the news and react in these ways:\n",
    "\n",
    "|    Stock Implication   |          Past          |         Present           |          Future          |\n",
    "| :--------------------: | :--------------------: | :-----------------------: | :----------------------: |\n",
    "| Artificially Increased |  Reduce Past Estimate  |  Reduce Present Estimate  |  Reduce Future Estimate  |\n",
    "| Artificially Decreased | Increase Past Estimate | Increase Present Estimate | Increase Future Estimate |\n",
    "|        No Change       |       Do Nothing       |         Do Nothing        |        Do Nothing        |\n",
    "\n",
    "This gives us an estimate and forecast of the *True* value of the stock, which we can use to make fat stacks.\n",
    "\n",
    "## Tools\n",
    "\n",
    "There are multiple different ways to get the stock prices; Bloomberg Terminals, and OpenBB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloomberg API\n",
    "\n",
    "Bloomberg terminals are the defacto way to get stock information. UW also provides access to 4 of these terminals in the MC building. The API for Bloomberg requires the terminal to be running, so the API can only run on a machine with the terminal open.\n",
    "\n",
    "For this reason, we are moving away from Bloomberg API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloomberg API\n",
    "\n",
    "from xbbg import blp\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = './Data/'\n",
    "\n",
    "tickers = ['NVDA US Equity', 'AAPL US Equity']\n",
    "fields = ['High', 'Low', 'Last_Price']\n",
    "start_date = '2024-11-01'\n",
    "end_date = '2024-11-10'\n",
    "\n",
    "# This line hangs unless it is running with a Bloomberg terminal\n",
    "hist_tick_data = blp.bdh(tickers=tickers, fields=fields, start_date=start_date, end_date=end_date)\n",
    "\n",
    "filename = f'tick_data_{start_date}_to_{end_date}.csv'\n",
    "hist_tick_data.to_csv(DATA_DIR + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenBB\n",
    "\n",
    "OpenBB is a free open-source implementation of Bloomberg's stock viewer. It can be run without any special software running in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openbb\n",
    "openbb.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            open  high   low  close     volume symbol\n",
      "date                                                 \n",
      "2010-01-04  7.63  7.66  7.59   7.64  493728200   AAPL\n",
      "2010-01-04  0.46  0.47  0.45   0.46  800352668   NVDA\n",
      "2010-01-05  7.67  7.70  7.62   7.66  601904016   AAPL\n",
      "2010-01-05  0.46  0.47  0.46   0.47  728697549   NVDA\n",
      "2010-01-06  7.66  7.69  7.53   7.54  552158376   AAPL\n"
     ]
    },
    {
     "ename": "OpenBBError",
     "evalue": "\n[Unexpected Error] -> InvalidIndexError -> Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenBBError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m start_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2010-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m end_date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2025-01-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 40\u001b[0m data_df \u001b[38;5;241m=\u001b[39m \u001b[43mdownloadStockData\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m data_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStock Data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(data_df)\n",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m, in \u001b[0;36mdownloadStockData\u001b[1;34m(symbol, start_date, end_date)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(ohlcv_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate RSI\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m rsi_data \u001b[38;5;241m=\u001b[39m \u001b[43mobb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtechnical\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mohlcv_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m rsi_df \u001b[38;5;241m=\u001b[39m rsi_data\u001b[38;5;241m.\u001b[39mto_df()\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrsi\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRSI_14\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Calculate MACD\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openbb_core\\app\\static\\utils\\decorators.py:101\u001b[0m, in \u001b[0;36mexception_handler.<locals>.wrapper\u001b[1;34m(*f_args, **f_kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m OpenBBError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[Error] -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, \u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m--> 101\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m OpenBBError(\n\u001b[0;32m    102\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[Unexpected Error] -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m         )\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3885\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3882\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_method(method, limit, tolerance)\n\u001b[0;32m   3884\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique:\n\u001b[1;32m-> 3885\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_unique_msg)\n\u001b[0;32m   3887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n",
      "\u001b[1;31mOpenBBError\u001b[0m: \n[Unexpected Error] -> InvalidIndexError -> Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "# OpenBB API\n",
    "\n",
    "from openbb import obb\n",
    "import pandas as pd\n",
    "\n",
    "obb.user.preferences.output_type = 'OBBject'\n",
    "\n",
    "def downloadStockData(symbol, start_date=None, end_date=None):\n",
    "    # Fetch daily OHLCV data\n",
    "    ohlcv_data = obb.equity.price.historical(symbol=symbol, start_date=start_date, end_date=end_date)\n",
    "    ohlcv_df = ohlcv_data.to_df()\n",
    "    print(ohlcv_df.head())\n",
    "\n",
    "    # Calculate RSI\n",
    "    rsi_data = obb.technical.rsi(data=ohlcv_data.results, target='close', length=14, scalar=100.0, drift=1)\n",
    "    rsi_df = rsi_data.to_df().rename(columns={'rsi': 'RSI_14'})\n",
    "\n",
    "    # Calculate MACD\n",
    "    macd_data = obb.technical.macd(data=ohlcv_data.results, target='close', fast=12, slow=26, signal=9)\n",
    "    macd_df = macd_data.to_df()\n",
    "\n",
    "    # Merge into main DataFrame\n",
    "    merged_df = ohlcv_df.merge(rsi_df, left_index=True, right_index=True)\n",
    "    merged_df = merged_df.merge(macd_df, left_index=True, right_index=True)\n",
    "\n",
    "    # Fetch S&P 500 data\n",
    "    sp500_data = obb.equity.price.historical(\"^GSPC\", start_date=start_date, end_date=end_date)\n",
    "    sp500_df = sp500_data.to_df()[['close']].rename(columns={'close': 'SP500'})\n",
    "\n",
    "    # Merge with OHLCV data\n",
    "    merged_df = merged_df.merge(sp500_df, left_index=True, right_index=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "# Declare search bounds \n",
    "symbols = ['AAPL', 'NVDA']\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2025-01-01'\n",
    "\n",
    "data_df = downloadStockData(symbols, start_date, end_date)\n",
    "\n",
    "data_df.to_csv('Stock Data.csv')\n",
    "print(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM pre-processing\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Declare search bounds \n",
    "symbols = ['AAPL', 'NVDA']\n",
    "start_date = '2024-11-01'\n",
    "end_date = '2024-11-10'\n",
    "\n",
    "# Get stock data\n",
    "data_df = downloadStockData(symbols, start_date, end_date)\n",
    "\n",
    "# Drop NA (from rolling indicators like MACD)\n",
    "data_df.dropna(inplace=True)\n",
    "\n",
    "# Select features (adjust as needed)\n",
    "features = ['open', 'high', 'low', 'close', 'volume', 'RSI_14', 'MACD_12_26', 'MACD_signal', 'SP500']\n",
    "target = 'close'\n",
    "\n",
    "# Normalize features (excluding target)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(data_df[features])\n",
    "\n",
    "def create_sequences(data, sequence_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        X.append(data[i:i+sequence_length])\n",
    "        y.append(data[i+sequence_length, 3])  # Assuming 'close' is the 4th column (index 3)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "sequence_length = 30  # Adjust based on your model\n",
    "X, y = create_sequences(scaled_features, sequence_length)\n",
    "\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(sequence_length, len(features))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
