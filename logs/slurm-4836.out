/var/lib/slurm/slurmd/job04836/slurm_script: line 20: module: command not found
+======================================================================================+
              Runing Script: Model/run_tests.py
+======================================================================================+
2025-02-23 02:42:52.094138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1740278572.105217  917727 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1740278572.108602  917727 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-23 02:42:52.136470: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
mkdir -p failed for path /home/ece498_w25_20/.config/matplotlib: [Errno 13] Permission denied: '/home/ece498_w25_20'
Matplotlib created a temporary cache directory at /tmp/matplotlib-ialczx_9 because there was an issue with the default path (/home/ece498_w25_20/.config/matplotlib); it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.
I0000 00:00:1740278578.007554  917727 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46645 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:51:00.0, compute capability: 8.6
Num GPUs Available: 1
Generated TAF parameter combinations:
[(0.1, 0.4, np.float64(0.005)), (0.1, 0.4, np.float64(0.01)), (0.1, 0.4, np.float64(0.015)), (0.1, 0.4, np.float64(0.02)), (0.1, 0.4, np.float64(0.025)), (0.1, 0.4, np.float64(0.03)), (0.1, 0.4, np.float64(0.035)), (0.1, 0.4, np.float64(0.04)), (0.1, 0.4, np.float64(0.045)), (0.1, 0.4, np.float64(0.05)), (0.1, 0.4, np.float64(0.055)), (0.1, 0.4, np.float64(0.06)), (0.1, 0.4, np.float64(0.065)), (0.1, 0.4, np.float64(0.07)), (0.1, 0.4, np.float64(0.075)), (0.1, 0.4, np.float64(0.08)), (0.1, 0.4, np.float64(0.085)), (0.1, 0.4, np.float64(0.09)), (0.1, 0.4, np.float64(0.095)), (0.1, 0.5, np.float64(0.005)), (0.1, 0.5, np.float64(0.01)), (0.1, 0.5, np.float64(0.015)), (0.1, 0.5, np.float64(0.02)), (0.1, 0.5, np.float64(0.025)), (0.1, 0.5, np.float64(0.03)), (0.1, 0.5, np.float64(0.035)), (0.1, 0.5, np.float64(0.04)), (0.1, 0.5, np.float64(0.045)), (0.1, 0.5, np.float64(0.05)), (0.1, 0.5, np.float64(0.055)), (0.1, 0.5, np.float64(0.06)), (0.1, 0.5, np.float64(0.065)), (0.1, 0.5, np.float64(0.07)), (0.1, 0.5, np.float64(0.075)), (0.1, 0.5, np.float64(0.08)), (0.1, 0.5, np.float64(0.085)), (0.1, 0.5, np.float64(0.09)), (0.1, 0.5, np.float64(0.095)), (0.1, 0.6, np.float64(0.005)), (0.1, 0.6, np.float64(0.01)), (0.1, 0.6, np.float64(0.015)), (0.1, 0.6, np.float64(0.02)), (0.1, 0.6, np.float64(0.025)), (0.1, 0.6, np.float64(0.03)), (0.1, 0.6, np.float64(0.035)), (0.1, 0.6, np.float64(0.04)), (0.1, 0.6, np.float64(0.045)), (0.1, 0.6, np.float64(0.05)), (0.1, 0.6, np.float64(0.055)), (0.1, 0.6, np.float64(0.06)), (0.1, 0.6, np.float64(0.065)), (0.1, 0.6, np.float64(0.07)), (0.1, 0.6, np.float64(0.075)), (0.1, 0.6, np.float64(0.08)), (0.1, 0.6, np.float64(0.085)), (0.1, 0.6, np.float64(0.09)), (0.1, 0.6, np.float64(0.095))]
*********** Starting New Cross-Validation ***********
Fold (Cross Validation) with train indices 0:7872 and test indices 7872:9920
trainX shape (After Reshape):  (3072, 4800, 1)
Model: "sequential"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ lstm (LSTM)                     â”‚ (256, 4800, 100)       â”‚        40,800 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lstm_1 (LSTM)                   â”‚ (256, 100)             â”‚        80,400 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                   â”‚ (256, 1)               â”‚           101 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 121,301 (473.83 KB)
 Trainable params: 121,301 (473.83 KB)
 Non-trainable params: 0 (0.00 B)
I0000 00:00:1740278581.269162  917912 cuda_dnn.cc:529] Loaded cuDNN version 90300
Model states reset
12/12 - 5s - 431ms/step - loss: 0.0166
Model states reset
Epoch 1/30 --- Completed
12/12 - 3s - 262ms/step - loss: 0.0042
Model states reset
Epoch 2/30 --- Completed
12/12 - 3s - 263ms/step - loss: 0.0031
Model states reset
Epoch 3/30 --- Completed
12/12 - 3s - 265ms/step - loss: 0.0029
Model states reset
Epoch 4/30 --- Completed
12/12 - 3s - 263ms/step - loss: 0.0026
Model states reset
Epoch 5/30 --- Completed
12/12 - 3s - 265ms/step - loss: 0.0025
Model states reset
Epoch 6/30 --- Completed
12/12 - 3s - 266ms/step - loss: 0.0024
Model states reset
Epoch 7/30 --- Completed
12/12 - 3s - 268ms/step - loss: 0.0023
Model states reset
Epoch 8/30 --- Completed
12/12 - 3s - 266ms/step - loss: 0.0022
Model states reset
Epoch 9/30 --- Completed
12/12 - 3s - 267ms/step - loss: 0.0020
Model states reset
Epoch 10/30 --- Completed
12/12 - 3s - 266ms/step - loss: 0.0019
Model states reset
Epoch 11/30 --- Completed
12/12 - 3s - 266ms/step - loss: 0.0017
Model states reset
Epoch 12/30 --- Completed
12/12 - 3s - 267ms/step - loss: 0.0015
Model states reset
Epoch 13/30 --- Completed
12/12 - 3s - 267ms/step - loss: 0.0012
Model states reset
Epoch 14/30 --- Completed
12/12 - 3s - 268ms/step - loss: 0.0010
Model states reset
Epoch 15/30 --- Completed
12/12 - 3s - 265ms/step - loss: 9.6348e-04
Model states reset
Epoch 16/30 --- Completed
12/12 - 3s - 266ms/step - loss: 9.3860e-04
Model states reset
Epoch 17/30 --- Completed
12/12 - 3s - 267ms/step - loss: 9.2033e-04
Model states reset
Epoch 18/30 --- Completed
12/12 - 3s - 267ms/step - loss: 9.0430e-04
Model states reset
Epoch 19/30 --- Completed
12/12 - 3s - 266ms/step - loss: 8.8963e-04
Model states reset
Epoch 20/30 --- Completed
12/12 - 3s - 265ms/step - loss: 8.7458e-04
Model states reset
Epoch 21/30 --- Completed
12/12 - 3s - 266ms/step - loss: 8.6020e-04
Model states reset
Epoch 22/30 --- Completed
12/12 - 3s - 266ms/step - loss: 8.4669e-04
Model states reset
Epoch 23/30 --- Completed
12/12 - 3s - 267ms/step - loss: 8.3313e-04
Model states reset
Epoch 24/30 --- Completed
12/12 - 3s - 269ms/step - loss: 8.1999e-04
Model states reset
Epoch 25/30 --- Completed
12/12 - 3s - 266ms/step - loss: 8.0690e-04
Model states reset
Epoch 26/30 --- Completed
12/12 - 3s - 267ms/step - loss: 7.9426e-04
Model states reset
Epoch 27/30 --- Completed
12/12 - 3s - 269ms/step - loss: 7.8178e-04
Model states reset
Epoch 28/30 --- Completed
12/12 - 3s - 267ms/step - loss: 7.6988e-04
Model states reset
Epoch 29/30 --- Completed
12/12 - 3s - 268ms/step - loss: 7.5798e-04
Model states reset
Epoch 30/30 --- Completed
[1m 1/12[0m [32mâ”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m2s[0m 189ms/step[1m 2/12[0m [32mâ”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m1s[0m 106ms/step[1m 3/12[0m [32mâ”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 103ms/step[1m 4/12[0m [32mâ”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 102ms/step[1m 5/12[0m [32mâ”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 101ms/step[1m 6/12[0m [32mâ”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”â”[0m [1m0s[0m 100ms/step[1m 7/12[0m [32mâ”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”â”â”[0m [1m0s[0m 100ms/step[1m 8/12[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”â”â”[0m [1m0s[0m 100ms/step[1m 9/12[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”â”[0m [1m0s[0m 99ms/step [1m10/12[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”â”â”[0m [1m0s[0m 99ms/step[1m11/12[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37mâ”â”[0m [1m0s[0m 99ms/step[1m12/12[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 99ms/step[1m12/12[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m1s[0m 100ms/step
Model: "sequential_1"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ lstm_2 (LSTM)                   â”‚ (256, 4800, 100)       â”‚        40,800 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lstm_3 (LSTM)                   â”‚ (256, 4800, 100)       â”‚        80,400 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)                 â”‚ (256, 4800, 1)         â”‚           101 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 121,301 (473.83 KB)
 Trainable params: 121,301 (473.83 KB)
 Non-trainable params: 0 (0.00 B)
Model: "sequential_2"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ lstm_4 (LSTM)                   â”‚ (256, 4800, 100)       â”‚        40,800 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ lstm_5 (LSTM)                   â”‚ (256, 4800, 100)       â”‚        80,400 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)                 â”‚ (256, 4800, 1)         â”‚           101 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 121,301 (473.83 KB)
 Trainable params: 121,301 (473.83 KB)
 Non-trainable params: 0 (0.00 B)
Future batch steps:  8
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 178ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 189ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 119ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 130ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 109ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 120ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 113ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 124ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 109ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 119ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 115ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 126ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 111ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 122ms/step
[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 115ms/step[1m1/1[0m [32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[0m[37m[0m [1m0s[0m 127ms/step
Forecast infered data shape:  (2048, 1)
TAF alpha=0.1, beta=0.4, weight=0.005: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.01: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.015: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.02: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.025: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.03: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.035: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.04: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.045: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.05: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.055: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.06: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.065: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.07: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.075: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.08: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.085: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.09: RMSE=78.99
TAF alpha=0.1, beta=0.4, weight=0.095: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.005: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.01: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.015: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.02: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.025: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.03: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.035: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.04: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.045: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.05: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.055: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.06: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.065: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.07: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.075: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.08: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.085: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.09: RMSE=78.99
TAF alpha=0.1, beta=0.5, weight=0.095: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.005: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.01: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.015: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.02: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.025: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.03: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.035: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.04: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.045: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.05: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.055: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.06: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.065: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.07: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.075: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.08: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.085: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.09: RMSE=78.99
TAF alpha=0.1, beta=0.6, weight=0.095: RMSE=78.99
Saved plot for column: B1
Cross-Validation RMSEs: 78.99394645245273
Saved plot for column: B1
Cross-Validation RMSEs: 78.99367381266241
Saved plot for column: B1
Cross-Validation RMSEs: 78.99340121831435
Saved plot for column: B1
Cross-Validation RMSEs: 78.99312866940903
Saved plot for column: B1
Cross-Validation RMSEs: 78.99285616594695
Saved plot for column: B1
Cross-Validation RMSEs: 78.99258370792853
Saved plot for column: B1
Cross-Validation RMSEs: 78.99231129535427
Saved plot for column: B1
Cross-Validation RMSEs: 78.99203892822464
Saved plot for column: B1
Cross-Validation RMSEs: 78.99176660654012
Saved plot for column: B1
Cross-Validation RMSEs: 78.99149433030115
Saved plot for column: B1
Cross-Validation RMSEs: 78.99122209950822
Saved plot for column: B1
Cross-Validation RMSEs: 78.99094991416179
Saved plot for column: B1
Cross-Validation RMSEs: 78.99067777426234
Saved plot for column: B1
Cross-Validation RMSEs: 78.99040567981035
Saved plot for column: B1
Cross-Validation RMSEs: 78.99013363080626
Saved plot for column: B1
Cross-Validation RMSEs: 78.98986162725055
Saved plot for column: B1
Cross-Validation RMSEs: 78.9895896691437
Saved plot for column: B1
Cross-Validation RMSEs: 78.98931775648617
Saved plot for column: B1
Cross-Validation RMSEs: 78.98904588927844
Saved plot for column: B1
Cross-Validation RMSEs: 78.99396592179261
Saved plot for column: B1
Cross-Validation RMSEs: 78.99371275004876
Saved plot for column: B1
Cross-Validation RMSEs: 78.99345962245377
Saved plot for column: B1
Cross-Validation RMSEs: 78.99320653900806
Saved plot for column: B1
Cross-Validation RMSEs: 78.99295349971204
Saved plot for column: B1
Cross-Validation RMSEs: 78.99270050456616
Saved plot for column: B1
Cross-Validation RMSEs: 78.99244755357081
Saved plot for column: B1
Cross-Validation RMSEs: 78.99219464672645
Saved plot for column: B1
Cross-Validation RMSEs: 78.99194178403347
Saved plot for column: B1
Cross-Validation RMSEs: 78.99168896549232
Saved plot for column: B1
Cross-Validation RMSEs: 78.99143619110342
Saved plot for column: B1
Cross-Validation RMSEs: 78.99118346086716
Saved plot for column: B1
Cross-Validation RMSEs: 78.99093077478402
Saved plot for column: B1
Cross-Validation RMSEs: 78.99067813285437
Saved plot for column: B1
Cross-Validation RMSEs: 78.99042553507869
Saved plot for column: B1
Cross-Validation RMSEs: 78.99017298145735
Saved plot for column: B1
Cross-Validation RMSEs: 78.9899204719908
Saved plot for column: B1
Cross-Validation RMSEs: 78.98966800667947
Saved plot for column: B1
Cross-Validation RMSEs: 78.98941558552377
Saved plot for column: B1
Cross-Validation RMSEs: 78.99405000055478
Saved plot for column: B1
Cross-Validation RMSEs: 78.99388091278323
Saved plot for column: B1
Cross-Validation RMSEs: 78.99371187437055
Saved plot for column: B1
Cross-Validation RMSEs: 78.99354288531701
Saved plot for column: B1
Cross-Validation RMSEs: 78.993373945623
Saved plot for column: B1
Cross-Validation RMSEs: 78.99320505528878
Saved plot for column: B1
Cross-Validation RMSEs: 78.99303621431469
Saved plot for column: B1
Cross-Validation RMSEs: 78.99286742270104
Saved plot for column: B1
Cross-Validation RMSEs: 78.99269868044814
Saved plot for column: B1
Cross-Validation RMSEs: 78.99252998755632
Saved plot for column: B1
Cross-Validation RMSEs: 78.99236134402588
Saved plot for column: B1
Cross-Validation RMSEs: 78.99219274985715
Saved plot for column: B1
Cross-Validation RMSEs: 78.99202420505046
Saved plot for column: B1
Cross-Validation RMSEs: 78.99185570960609
Saved plot for column: B1
Cross-Validation RMSEs: 78.99168726352437
Saved plot for column: B1
Cross-Validation RMSEs: 78.99151886680562
Saved plot for column: B1
Cross-Validation RMSEs: 78.99135051945015
Saved plot for column: B1
Cross-Validation RMSEs: 78.99118222145829
Saved plot for column: B1
Cross-Validation RMSEs: 78.99101397283036
+===========================================+
Runtime for: Model/run_tests.py
-----------> 00d:00h:03m:00s
+===========================================+
